{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Extract error types from: \"conll14st-preprocessed.conll.ann\" file\n",
    "# Separate each word of a particular error type in its own list.\n",
    "l1=[]\n",
    "l4=[]\n",
    "l5=[]\n",
    "l6=[]\n",
    "l7=[]\n",
    "l11=[]\n",
    "l14=[]\n",
    "def extract_err_type(colnn_ann):\n",
    "    f = open(colnn_ann, 'r')\n",
    "    for line in f:\n",
    "        parts = line.split()\n",
    "        if(len(parts)>0):\n",
    "            if(line[0:6]==\"<TYPE>\"):\n",
    "                type_ = line[6:len(parts[0])-7]\n",
    "            elif(line[0:12]==\"<CORRECTION>\"):\n",
    "                corrected_word = line[12:len(line)-14] \n",
    "                if type_ ==\"Vt\":\n",
    "                    \"Vt\", line[12:len(line)-14]\n",
    "                    l1.append(line[12:len(line)-14])   \n",
    "                if type_ ==\"Vform\":\n",
    "                    l4.append(line[12:len(line)-14])\n",
    "                if type_ ==\"SVA\":\n",
    "                    l5.append(line[12:len(line)-14])\n",
    "                if type_ ==\"ArtOrDet\":\n",
    "                    l6.append(line[12:len(line)-14])\n",
    "                if type_ ==\"Nn\":\n",
    "                    l7.append(line[12:len(line)-14])\n",
    "                if type_ ==\"Prep\":\n",
    "                    l11.append(line[12:len(line)-14])\n",
    "                if type_ ==\"Wform\":\n",
    "                    l14.append(line[12:len(line)-14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass in to the function, the path to conll14st-preprocessed.conll.ann in your system\n",
    "extract_err_type(\"/Users/highsierra/Tech-Skills/Labortory/ML-Fundamentals/error_types_conll14/conll14st-preprocessed.conll.ann\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a corresponding list containing the error type of each word\n",
    "# Map between each word and its error type\n",
    "ll1=[]\n",
    "for i in range(len(l1)):\n",
    "    ll1.append('Vt')\n",
    "\n",
    "ll4=[]\n",
    "for i in range(len(l4)):\n",
    "    ll4.append('Vform')\n",
    "\n",
    "ll5=[]\n",
    "for i in range(len(l5)):\n",
    "    ll5.append('SVA')\n",
    "\n",
    "ll6=[]\n",
    "for i in range(len(l6)):\n",
    "    ll6.append('ArtOrDet')\n",
    "\n",
    "ll7=[]\n",
    "for i in range(len(l7)):\n",
    "    ll7.append('Nn')\n",
    "\n",
    "ll11=[]\n",
    "for i in range(len(l11)):\n",
    "    ll11.append('Prep')\n",
    "\n",
    "\n",
    "ll14=[]\n",
    "for i in range(len(l14)):\n",
    "    ll14.append('Wform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the words (input) from the error types (target)\n",
    "import itertools\n",
    "\n",
    "targets = list(itertools.chain(ll1, ll4, ll5, ll6, ll7, ll11, ll14))\n",
    "words = list(itertools.chain(l1, l4, l5, l6, l7, l11, l14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21138\n"
     ]
    }
   ],
   "source": [
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Encode the input using glove embeddings   \n",
    "\n",
    "from zeugma.embeddings import EmbeddingTransformer\n",
    "\n",
    "glove = EmbeddingTransformer('glove') \n",
    "X = glove.transform(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.4602001e-04 -8.4354997e-02  1.9994000e-01 ...  2.7858001e-01\n",
      "   2.0168000e-01 -7.1859002e-01]\n",
      " [ 5.7466000e-02  1.7890000e-01 -6.2778002e-01 ... -7.5557001e-02\n",
      "   2.4191999e-01  2.2470001e-03]\n",
      " [-5.2309000e-01 -6.8026000e-01 -4.6072000e-01 ...  5.2221000e-01\n",
      "   7.0643997e-01 -2.5231999e-01]\n",
      " ...\n",
      " [ 5.6629997e-01  2.5286999e-01 -1.1373000e+00 ...  5.4163003e-01\n",
      "  -1.7024000e+00 -4.1539001e-01]\n",
      " [ 3.4362650e-01  9.2356995e-02 -6.9733500e-01 ... -3.7974998e-02\n",
      "  -1.1478500e+00 -2.5225499e-01]\n",
      " [ 1.0357000e-01  5.4285997e-01 -8.8192999e-01 ... -4.9219000e-01\n",
      "   1.3172001e-01 -8.6390001e-01]]\n",
      "(21138, 25)\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21138\n"
     ]
    }
   ],
   "source": [
    "print(len(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]]\n",
      "(21138, 7)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "ybin = lb.fit(targets)\n",
    "lb.classes_\n",
    "\n",
    "y = lb.transform(targets)\n",
    "print(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import SpatialDropout1D\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 1, 25)\n",
    "X_test  = X_test.reshape(-1, 1, 25)\n",
    "y_train = y_train.reshape(-1, 1, 7)\n",
    "y_test = y_test.reshape(-1, 1, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/miniconda3/envs/tensorflow1/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(200, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/miniconda3/envs/tensorflow1/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /opt/miniconda3/envs/tensorflow1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/25\n",
      "16910/16910 [==============================] - 13s 747us/step - loss: 1.2749 - accuracy: 0.5731\n",
      "Epoch 2/25\n",
      "16910/16910 [==============================] - 8s 465us/step - loss: 1.0106 - accuracy: 0.6443\n",
      "Epoch 3/25\n",
      "16910/16910 [==============================] - 7s 443us/step - loss: 0.9650 - accuracy: 0.6560\n",
      "Epoch 4/25\n",
      "16910/16910 [==============================] - 8s 446us/step - loss: 0.9424 - accuracy: 0.6658\n",
      "Epoch 5/25\n",
      "16910/16910 [==============================] - 8s 448us/step - loss: 0.9197 - accuracy: 0.6726\n",
      "Epoch 6/25\n",
      "16910/16910 [==============================] - 8s 455us/step - loss: 0.9071 - accuracy: 0.6737\n",
      "Epoch 7/25\n",
      "16910/16910 [==============================] - 8s 449us/step - loss: 0.8981 - accuracy: 0.6800\n",
      "Epoch 8/25\n",
      "16910/16910 [==============================] - 10s 585us/step - loss: 0.8857 - accuracy: 0.6827\n",
      "Epoch 9/25\n",
      "16910/16910 [==============================] - 8s 473us/step - loss: 0.8754 - accuracy: 0.6866\n",
      "Epoch 10/25\n",
      "16910/16910 [==============================] - 8s 470us/step - loss: 0.8697 - accuracy: 0.6877\n",
      "Epoch 11/25\n",
      "16910/16910 [==============================] - 8s 463us/step - loss: 0.8666 - accuracy: 0.6915\n",
      "Epoch 12/25\n",
      "16910/16910 [==============================] - 8s 465us/step - loss: 0.8602 - accuracy: 0.6920\n",
      "Epoch 13/25\n",
      "16910/16910 [==============================] - 8s 472us/step - loss: 0.8558 - accuracy: 0.6934\n",
      "Epoch 14/25\n",
      "16910/16910 [==============================] - 10s 575us/step - loss: 0.8470 - accuracy: 0.6953\n",
      "Epoch 15/25\n",
      "16910/16910 [==============================] - 8s 487us/step - loss: 0.8485 - accuracy: 0.6946\n",
      "Epoch 16/25\n",
      "16910/16910 [==============================] - 8s 468us/step - loss: 0.8430 - accuracy: 0.6996\n",
      "Epoch 17/25\n",
      "16910/16910 [==============================] - 8s 497us/step - loss: 0.8402 - accuracy: 0.6970\n",
      "Epoch 18/25\n",
      "16910/16910 [==============================] - 8s 465us/step - loss: 0.8337 - accuracy: 0.6966\n",
      "Epoch 19/25\n",
      "16910/16910 [==============================] - 8s 462us/step - loss: 0.8316 - accuracy: 0.7041\n",
      "Epoch 20/25\n",
      "16910/16910 [==============================] - 8s 465us/step - loss: 0.8305 - accuracy: 0.6984\n",
      "Epoch 21/25\n",
      "16910/16910 [==============================] - 10s 594us/step - loss: 0.8249 - accuracy: 0.7042\n",
      "Epoch 22/25\n",
      "16910/16910 [==============================] - 8s 470us/step - loss: 0.8205 - accuracy: 0.7063\n",
      "Epoch 23/25\n",
      "16910/16910 [==============================] - 8s 475us/step - loss: 0.8205 - accuracy: 0.7051\n",
      "Epoch 24/25\n",
      "16910/16910 [==============================] - 8s 490us/step - loss: 0.8213 - accuracy: 0.7021\n",
      "Epoch 25/25\n",
      "16910/16910 [==============================] - 8s 488us/step - loss: 0.8171 - accuracy: 0.7067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a7287e690>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=25, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.59%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow1)",
   "language": "python",
   "name": "tensorflow1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
